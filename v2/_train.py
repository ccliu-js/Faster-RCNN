import torch
from tqdm import tqdm
from torchmetrics.detection.mean_ap import MeanAveragePrecision

class FasterRCNNTrainer:
    def __init__(self, model, lr=0.005, ckpt_path="weight/best_model.pth", device=None, grad_clip=None):
        """
        grad_clip: 
            float or None, å¦‚æœä¸ä¸º Noneï¼Œåˆ™å¯¹æ¢¯åº¦è¿›è¡Œè£å‰ª
            æ¢¯åº¦è£å‰ªï¼Œé™åˆ¶æ¢¯åº¦çš„æœ€å¤§å€¼ï¼Œé˜²æ­¢æ¢¯åº¦ä¸ç¨³å®š æˆ–è€… lossçˆ†ç‚¸ã€‚
            é€šä¿—ç‚¹è®²ï¼šé™åˆ¶æ¢¯åº¦çš„æ›´æ–°çš„å¹…åº¦ï¼Œé™ä½å‚æ•°è·³å˜çš„å¹…åº¦ï¼ˆå¯ä»¥ä»å­¦ä¹ ç‡è¿™ç§ç±»ä¼¼çš„æ€æƒ³å»ç†è§£ï¼‰

            ä½¿ç”¨åŸå› ï¼š
                1.åœ¨å° batch æˆ–å¤§ loss çš„æƒ…å†µä¸‹ï¼Œæ¢¯åº¦å¯èƒ½ä¼šéå¸¸å¤§ï¼ˆæ¢¯åº¦çˆ†ç‚¸ï¼‰
                2.ç›´æ¥ç”¨æ¢¯åº¦æ›´æ–°å‚æ•°ï¼Œä¼šå¯¼è‡´æ¨¡å‹å‚æ•°å˜åŒ–è¿‡å¤§ â†’ loss NaN æˆ–è®­ç»ƒä¸ç¨³å®š
                3.è£å‰ªæ¢¯åº¦å¯ä»¥é™åˆ¶æ¯æ¬¡æ›´æ–°çš„æœ€å¤§å¹…åº¦ï¼Œä½¿è®­ç»ƒæ›´åŠ ç¨³å®š

        """
        self.model = model
        self.device = device if device else torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)

        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=lr, momentum=0.9, weight_decay=0.0005)
        self.lr_scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=3, gamma=0.1)

        self.ckpt_path = ckpt_path
        self.best_loss = float("inf")###ç”¨äºæš‚å­˜ å½“å‰æ¨¡å‹çš„lossçš„ï¼Œä¾¿äºåç»­çš„å„ç§åˆ†æå’Œå¤„ç†
        self.grad_clip = grad_clip

    def train_one_epoch(self, data_loader, epoch):
        self.model.train()
        total_loss = 0

        loop = tqdm(data_loader, desc=f"Epoch {epoch} [Train]", leave=False)
        for images, targets in loop:
            loss_dict = self.model(images, targets)
            losses = sum(loss for loss in loss_dict.values())

            self.optimizer.zero_grad()
            losses.backward()

            if self.grad_clip is not None:
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip)

            self.optimizer.step()
            total_loss += losses.item()

            loop.set_postfix(loss=losses.item())

        avg_loss = total_loss / len(data_loader)
        print(f"[Epoch {epoch}] Training Loss: {avg_loss:.4f}")
        return avg_loss

 
    def validate(self, data_loader, epoch):
        self.model.eval()
        device = self.device   # å‡è®¾ä½ åœ¨ Trainer åˆå§‹åŒ–æ—¶å°±æœ‰ self.device
        all_predictions = []
        all_targets = []

        loop = tqdm(data_loader, desc=f"Epoch {epoch} [Val]", leave=False)

        with torch.no_grad():
            for images, targets in loop:
                # æŠŠæ¯å¼ å›¾åƒæ¬åˆ° GPU
                images = [img.to(device) for img in images]

                # æŠŠ targets çš„æ¯ä¸ª dict æ¬åˆ° GPU
                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

                # æ¨ç†
                predictions = self.model(images)

                # ç¡®ä¿é¢„æµ‹ç»“æœä¹Ÿåœ¨ GPU
                predictions = [{k: v.to(device) for k, v in p.items()} for p in predictions]

                # æ”¶é›†ç»“æœ
                all_predictions.extend(predictions)
                all_targets.extend(targets)

        # åˆå§‹åŒ–è¯„ä¼°å™¨
        metric = MeanAveragePrecision(class_metrics=True)
        # æ›´æ–°ç»“æœ
        metric.update(all_predictions, all_targets)
        # è®¡ç®—æœ€ç»ˆç»“æœ
        res = metric.compute()

        print(f"\nğŸ“Š [Epoch {epoch}] - Validation Mean Average Precision Results")
        print("-" * 40)
        for k, v in res.items():
            if isinstance(v, torch.Tensor):
                if v.numel() == 1:  # åªæœ‰ä¸€ä¸ªå…ƒç´ ï¼Œå¯ä»¥å®‰å…¨è½¬æˆ float
                    val = v.item()
                    if val == -1.0:
                        print(f"{k:<20}: N/A")
                    else:
                        print(f"{k:<20}: {val:.4f}")
                else:
                    # å¤šç±»åˆ«çš„æƒ…å†µï¼Œæ‰“å°å‰å‡ ä¸ªï¼Œæˆ–è€…å…¨éƒ¨
                    print(f"{k:<20}: {v.tolist()}")
            else:
                print(f"{k:<20}: {v}")

        return res["map"].item()




    def save_checkpoint(self):
        torch.save(self.model.state_dict(), self.ckpt_path)

    def load_checkpoint(self):
        try:
            self.model.load_state_dict(torch.load(self.ckpt_path, map_location=self.device))
            print(f"ğŸ”„ Loaded checkpoint from {self.ckpt_path}")
        except FileNotFoundError:
            print("âš ï¸ No checkpoint found, starting from scratch.")

    # =========================
    # æ–°å¢ fit æ–¹æ³•
    # =========================
    def fit(self, train_loader, val_loader, epochs):
        # å‚¨å­˜è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ•°æ®ï¼Œä¾¿äºåç»­è¿›è¡Œåˆ†æè®­ç»ƒè¿‡ç¨‹ å’Œ åšå¥½å¯è§†åŒ–
        best_train_loss = float("inf")  # åˆå§‹åŒ–æœ€å¥½çš„è®­ç»ƒæŸå¤±ä¸ºæ— ç©·å¤§
        for epoch in range(1, epochs + 1):
            train_loss = self.train_one_epoch(train_loader, epoch)

            # å¦‚æœå½“å‰è®­ç»ƒæŸå¤±ä¼˜äºå†å²æœ€ä½³æŸå¤±ï¼Œåˆ™ä¿å­˜æ¨¡å‹
            if train_loss < best_train_loss:
                best_train_loss = train_loss
                # self.save_checkpoint()  # ä¿å­˜å½“å‰æ¨¡å‹
                self.validate(val_loader, epoch)

            self.lr_scheduler.step()## è¿™ä¸ªæ˜¯ä»€ä¹ˆï¼Ÿï¼Ÿä¼šæœ‰ä»€ä¹ˆç”¨å¤„ï¼Ÿï¼Ÿ
